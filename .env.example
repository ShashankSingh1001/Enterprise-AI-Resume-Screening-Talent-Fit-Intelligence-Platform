# ========================================
# Enterprise AI Resume Screening Platform
# Environment Variables Template
# ========================================
# 
# INSTRUCTIONS:
# 1. Copy this file and rename it to .env
# 2. Fill in your actual values
# 3. Never commit .env to Git (already in .gitignore)
# ========================================

# ============ Application Settings ============
APP_NAME="Resume AI Platform"
APP_VERSION="1.0.0"
ENVIRONMENT="development"  # development, staging, production
DEBUG=True

# ============ API Settings ============
API_HOST="0.0.0.0"
API_PORT=8000
API_RELOAD=True  # Set to False in production

# ============ Streamlit Settings ============
STREAMLIT_HOST="0.0.0.0"
STREAMLIT_PORT=8501

# ============ Database Configuration ============
# PostgreSQL Connection
DATABASE_HOST="localhost"
DATABASE_PORT=5432
DATABASE_NAME="resume_ai"
DATABASE_USER="postgres"
DATABASE_PASSWORD="your_password_here"
DATABASE_URL="postgresql://${DATABASE_USER}:${DATABASE_PASSWORD}@${DATABASE_HOST}:${DATABASE_PORT}/${DATABASE_NAME}"

# Connection Pool Settings
DB_POOL_SIZE=5
DB_MAX_OVERFLOW=10

# ============ MLflow Configuration ============
MLFLOW_TRACKING_URI="http://localhost:5000"
MLFLOW_EXPERIMENT_NAME="resume_screening"
MLFLOW_REGISTRY_URI="sqlite:///mlruns.db"

# Model Registry
MLFLOW_MODEL_NAME="resume_fit_classifier"
MLFLOW_MODEL_STAGE="Production"  # Staging, Production, Archived

# ============ DVC Configuration ============
# Leave empty for local storage, or configure remote storage
DVC_REMOTE_URL=""
# Examples:
# DVC_REMOTE_URL="s3://my-bucket/dvc-storage"
# DVC_REMOTE_URL="gs://my-bucket/dvc-storage"
# DVC_REMOTE_URL="azure://my-container/dvc-storage"

# ============ JWT Authentication ============
# Generate a secure key: python -c "import secrets; print(secrets.token_urlsafe(32))"
SECRET_KEY="your-secret-key-change-this-in-production"
ALGORITHM="HS256"
ACCESS_TOKEN_EXPIRE_MINUTES=30

# ============ File Upload Settings ============
MAX_UPLOAD_SIZE_MB=10
ALLOWED_RESUME_FORMATS="pdf,docx,doc,txt"
UPLOAD_DIR="data/uploads"

# ============ Model Settings ============
# Sentence-BERT Model
SBERT_MODEL_NAME="all-MiniLM-L6-v2"
SBERT_CACHE_DIR="models/sbert_cache"

# spaCy Model
SPACY_MODEL="en_core_web_sm"

# ML Model
DEFAULT_MODEL_PATH="models/xgboost_model.pkl"
MODEL_THRESHOLD=0.5  # Classification threshold

# ============ Feature Engineering ============
MIN_EXPERIENCE_YEARS=0
MAX_EXPERIENCE_YEARS=50
SKILL_MATCH_WEIGHT=0.4
EXPERIENCE_WEIGHT=0.3
EDUCATION_WEIGHT=0.2
SIMILARITY_WEIGHT=0.1

# ============ Logging Configuration ============
LOG_LEVEL="INFO"  # DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_FILE_PATH="logs/app.log"
LOG_MAX_BYTES=10485760  # 10MB
LOG_BACKUP_COUNT=5
LOG_FORMAT="%(asctime)s - %(name)s - %(levelname)s - %(message)s"

# ============ CORS Settings ============
CORS_ORIGINS="http://localhost:3000,http://localhost:8501"
CORS_ALLOW_CREDENTIALS=True
CORS_ALLOW_METHODS="*"
CORS_ALLOW_HEADERS="*"

# ============ Explainability Settings ============
SHAP_SAMPLE_SIZE=100
LIME_NUM_FEATURES=10
LIME_NUM_SAMPLES=1000

# ============ Bias Audit Settings ============
BIAS_SENSITIVE_FEATURES="gender,university_tier,years_of_experience"
FAIRNESS_THRESHOLD=0.8  # Disparate impact ratio threshold

# ============ Cache Settings ============
ENABLE_CACHE=True
CACHE_TTL=3600  # seconds
REDIS_HOST="localhost"
REDIS_PORT=6379
REDIS_DB=0

# ============ External API Keys (if needed) ============
# OpenAI (for advanced NLP - optional)
OPENAI_API_KEY=""

# AWS (if using S3 for storage)
AWS_ACCESS_KEY_ID=""
AWS_SECRET_ACCESS_KEY=""
AWS_REGION="us-east-1"
AWS_S3_BUCKET=""

# Google Cloud (if using GCS)
GOOGLE_APPLICATION_CREDENTIALS=""
GCS_BUCKET_NAME=""

# ============ Monitoring & Analytics ============
# Sentry Error Tracking (optional)
SENTRY_DSN=""

# Google Analytics (optional)
GA_TRACKING_ID=""

# ============ Email Notifications (optional) ============
SMTP_HOST="smtp.gmail.com"
SMTP_PORT=587
SMTP_USER=""
SMTP_PASSWORD=""
SMTP_FROM_EMAIL=""

# ============ Deployment Settings ============
# For Render.com / Cloud Deployment
RENDER_EXTERNAL_URL=""
STREAMLIT_CLOUD_URL=""

# ============ Testing Settings ============
TEST_DATABASE_URL="postgresql://postgres:postgres@localhost:5432/resume_ai_test"
TEST_MODE=False

# ============ Performance Settings ============
WORKER_THREADS=4
MAX_CONCURRENT_REQUESTS=100
REQUEST_TIMEOUT=300  # seconds

# ============ Data Paths ============
RAW_DATA_PATH="data/raw"
PROCESSED_DATA_PATH="data/processed"
FEATURES_DATA_PATH="data/features"
MODELS_PATH="models"
LOGS_PATH="logs"

# ============ Feature Flags ============
ENABLE_BIAS_AUDIT=True
ENABLE_EXPLAINABILITY=True
ENABLE_USER_AUTH=True
ENABLE_EMAIL_NOTIFICATIONS=False